### Лабораторная работа №5
## Исследование инструментов классификации библиотеки Scikit-learn  

В даннной лаборатоной работе использовались следующие классифокаторы:  
 - Линейный дискриминантный анализ (Linear Discriminant Analysis);  
 - Метод опорных векторов (Support Vector Machines);
 - Наивный байесовский классификатор (Naive Bayes).

Использовался dataset ["Прогноз инсульта"](https://www.kaggle.com/datasets/prosperchuks/health-dataset).
За результирующий (целевой) столбец был взят столбец 'stroke', так как именно он определяет есть ли у человека инсульт.
За набор признаков были взяты все остальные столбцы, так как эти признаки на прямую или косвенно влияют на появление инсульта у человека.

 ## Линейный дискриминантный анализ (Linear Discriminant Analysis)
Линейный дискриминантный анализ является методом классификации, основанным на анализе статистических характеристик выборки наблюдений.
Вследствие этого основным достоинством ЛДА является то, что для одной и той же выборки всегда будет получаться одна и та же модель классификатора. Тем самым за счет отсутствия случайной составляющей в методе его можно использовать как эталон для сравнения с методами классификации, имеющими случайную составляющую, например, с нейронными сетями. 
С другой стороны, недостатком ЛДА можно считать то, что не всегда есть возможность провести анализ, если между признаками наблюдается сильная корреляция.

Получены следующие результаты:
![](https://i.imgur.com/BQqUTxh.jpg)
![](https://i.imgur.com/VsPjLO5.jpg)

## Метод опорных векторов (Support Vector Machines)
SVM отличается от других алгоритмов классификации тем, что он выбирает границу решения, которая максимизирует расстояние от ближайших точек данных всех классов. SVM не просто находит границу принятия решения, он находит наиболее оптимальную границу решения.    
Самая оптимальная граница решения – это та, которая имеет максимальный запас от ближайших точек всех классов. Ближайшие точки от границы решения, которые максимизируют расстояние между границей решения и точками, называются опорными векторами. Граница решения в случае машин с опорными векторами называется классификатором максимальной маржи или гиперплоскостью максимальной маржи.

Получены следующие результаты:
![](https://i.imgur.com/YuPnAmJ.jpg)  
![](https://i.imgur.com/eQnhzWb.jpg)

## Наивный байесовский классификатор (Naive Bayes)
Наивный байесовский классификатор является простым вероятностным классификатором, который основан на применении теоремы Байеса со строгими (наивными) предположениями о независимости.
В зависимости от точной природы вероятностной модели, наивные байесовские классификаторы могут обучаться очень эффективно. Во многих практических приложениях для оценки параметров для наивных байесовых моделей используют метод максимального правдоподобия; другими словами, можно работать с наивной байесовской моделью, не веря в байесовскую вероятность и не используя байесовские методы.
Несмотря на наивный вид и, несомненно, очень упрощенные условия, наивные байесовские классификаторы часто работают намного лучше нейронных сетей во многих сложных жизненных ситуациях.
Достоинством наивного байесовского классификатора является малое количество данных, необходимых для обучения, оценки параметров и классификации.

Получены следующие результаты:
![](https://i.imgur.com/tq5OHOS.jpg)  
![](https://i.imgur.com/IjG9L8O.jpg)

## Результат
Точность моделей является, по большей части, сходится с остальными.
Максимальная точность равна ~70%, что является хорошим результатом.